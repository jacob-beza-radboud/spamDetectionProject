{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Spam Detection Project\n",
    "In the era of internet we are able to easily search for information, communicate with one another or even shop on any place on the earth with just a few strokes on the keyboard of our computer. Unfortunately, the same thing that makes our life easier, also introduces new ways on information gathering on people. The most common way to do that these days is by using 'spam' messages, email, social media accounts, ect. When 'spam' is shown to us, sometimes it looks really convincing as if it was a real product, message or email. Therefore we click on it to find out more without realising how much we revel about ourselves.\n",
    "\n",
    "'Spam' is a huge problem in the current days of the internet. That's why we decided to try to create a program that would be able to scan through many messages, emails, etc. and detect which ones most likely fit the 'spam' profile.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### spam data (MLP model)\n",
    "At this cell we load all the necessary files and convert them."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jakub\\AppData\\Local\\Temp\\ipykernel_30980\\3718110973.py:18: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  text_np = np.asarray(text)\n"
     ]
    }
   ],
   "source": [
    "from numpy.ma import indices\n",
    "import numpy as np\n",
    "from toolbox.load_assets import load_spam\n",
    "from toolbox.prepare_data import prepare\n",
    "from toolbox.conversion import conversion\n",
    "from toolbox.reshape import reshape\n",
    "#------------------------------\n",
    "file = \"./data/spam.csv\"\n",
    "X = \"./data/train.csv\"\n",
    "#------------------------------\n",
    "\n",
    "spam_dic = load_spam(file)\n",
    "\n",
    "data = prepare(X,'spam_text','label')\n",
    "text =  data[0]\n",
    "labels = data[1]\n",
    "\n",
    "text_np = np.asarray(text)\n",
    "labels_np = np.asarray(labels)\n",
    "\n",
    "converted_data = conversion(spam_dic, text_np)\n",
    "reshape(converted_data)\n",
    "\n",
    "converted_data_np = np.asarray(converted_data)\n",
    "\n",
    "NR_FEATURES = len(converted_data[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## MLP spam detection\n",
    "Our first model is an 'MLP' classifier. But in order to find out what are the bets values for our 'object' we decided to run some tests firstly."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained with layer=10, KFold split 1\n",
      "Model trained with layer=11, KFold split 1\n",
      "Model trained with layer=12, KFold split 1\n",
      "Model trained with layer=13, KFold split 1\n",
      "Model trained with layer=14, KFold split 1\n",
      "Model trained with layer=15, KFold split 1\n",
      "Model trained with layer=16, KFold split 1\n",
      "Model trained with layer=17, KFold split 1\n",
      "Model trained with layer=18, KFold split 1\n",
      "Model trained with layer=19, KFold split 1\n",
      "Model trained with layer=20, KFold split 1\n",
      "Model trained with layer=21, KFold split 1\n",
      "Model trained with layer=22, KFold split 1\n",
      "Model trained with layer=23, KFold split 1\n",
      "Model trained with layer=24, KFold split 1\n",
      "Model trained with layer=25, KFold split 1\n",
      "Model trained with layer=10, KFold split 2\n",
      "Model trained with layer=11, KFold split 2\n",
      "Model trained with layer=12, KFold split 2\n",
      "Model trained with layer=13, KFold split 2\n",
      "Model trained with layer=14, KFold split 2\n",
      "Model trained with layer=15, KFold split 2\n",
      "Model trained with layer=16, KFold split 2\n",
      "Model trained with layer=17, KFold split 2\n",
      "Model trained with layer=18, KFold split 2\n",
      "Model trained with layer=19, KFold split 2\n",
      "Model trained with layer=20, KFold split 2\n",
      "Model trained with layer=21, KFold split 2\n",
      "Model trained with layer=22, KFold split 2\n",
      "Model trained with layer=23, KFold split 2\n",
      "Model trained with layer=24, KFold split 2\n",
      "Model trained with layer=25, KFold split 2\n",
      "Model trained with layer=10, KFold split 3\n",
      "Model trained with layer=11, KFold split 3\n",
      "Model trained with layer=12, KFold split 3\n",
      "Model trained with layer=13, KFold split 3\n",
      "Model trained with layer=14, KFold split 3\n",
      "Model trained with layer=15, KFold split 3\n",
      "Model trained with layer=16, KFold split 3\n",
      "Model trained with layer=17, KFold split 3\n",
      "Model trained with layer=18, KFold split 3\n",
      "Model trained with layer=19, KFold split 3\n",
      "Model trained with layer=20, KFold split 3\n",
      "Model trained with layer=21, KFold split 3\n",
      "Model trained with layer=22, KFold split 3\n",
      "Model trained with layer=23, KFold split 3\n",
      "Model trained with layer=24, KFold split 3\n",
      "Model trained with layer=25, KFold split 3\n",
      "Model trained with layer=10, KFold split 4\n",
      "Model trained with layer=11, KFold split 4\n",
      "Model trained with layer=12, KFold split 4\n",
      "Model trained with layer=13, KFold split 4\n",
      "Model trained with layer=14, KFold split 4\n",
      "Model trained with layer=15, KFold split 4\n",
      "Model trained with layer=16, KFold split 4\n",
      "Model trained with layer=17, KFold split 4\n",
      "Model trained with layer=18, KFold split 4\n",
      "Model trained with layer=19, KFold split 4\n",
      "Model trained with layer=20, KFold split 4\n",
      "Model trained with layer=21, KFold split 4\n",
      "Model trained with layer=22, KFold split 4\n",
      "Model trained with layer=23, KFold split 4\n",
      "Model trained with layer=24, KFold split 4\n",
      "Model trained with layer=25, KFold split 4\n",
      "Model trained with layer=10, KFold split 5\n",
      "Model trained with layer=11, KFold split 5\n",
      "Model trained with layer=12, KFold split 5\n",
      "Model trained with layer=13, KFold split 5\n",
      "Model trained with layer=14, KFold split 5\n",
      "Model trained with layer=15, KFold split 5\n",
      "Model trained with layer=16, KFold split 5\n",
      "Model trained with layer=17, KFold split 5\n",
      "Model trained with layer=18, KFold split 5\n",
      "Model trained with layer=19, KFold split 5\n",
      "Model trained with layer=20, KFold split 5\n",
      "Model trained with layer=21, KFold split 5\n",
      "Model trained with layer=22, KFold split 5\n",
      "Model trained with layer=23, KFold split 5\n",
      "Model trained with layer=24, KFold split 5\n",
      "Model trained with layer=25, KFold split 5\n",
      "[[(10, 0.09417040358744395), (11, 0.09237668161434978), (12, 0.09327354260089686), (13, 0.09147982062780269), (14, 0.09147982062780269), (15, 0.09327354260089686), (16, 0.09327354260089686), (17, 0.09327354260089686), (18, 0.09327354260089686), (19, 0.09417040358744395), (20, 0.09327354260089686), (21, 0.09147982062780269), (22, 0.09147982062780269), (23, 0.09147982062780269), (24, 0.09417040358744395), (25, 0.09417040358744395)], [(10, 0.06852017937219727), (11, 0.06816143497757843), (12, 0.06852017937219727), (13, 0.06816143497757843), (14, 0.0688789237668161), (15, 0.0688789237668161), (16, 0.06816143497757843), (17, 0.06905829596412556), (18, 0.06816143497757843), (19, 0.06852017937219727), (20, 0.06852017937219727), (21, 0.06941704035874437), (22, 0.06852017937219727), (23, 0.06816143497757843), (24, 0.0688789237668161), (25, 0.06816143497757843)], [(10, 0.07659192825112104), (11, 0.07730941704035872), (12, 0.07659192825112104), (13, 0.07641255605381163), (14, 0.07748878923766814), (15, 0.07766816143497754), (16, 0.07605381165919278), (17, 0.07605381165919278), (18, 0.07569506726457395), (19, 0.07569506726457395), (20, 0.07677130044843046), (21, 0.0762331838565022), (22, 0.07748878923766814), (23, 0.0753363228699551), (24, 0.07713004484304928), (25, 0.07784753363228696)], [(10, 0.08304932735426007), (11, 0.08376681614349775), (12, 0.08304932735426007), (13, 0.08376681614349775), (14, 0.0791031390134529), (15, 0.08376681614349775), (16, 0.08107623318385648), (17, 0.08502242152466366), (18, 0.07982062780269057), (19, 0.0791031390134529), (20, 0.08502242152466366), (21, 0.0791031390134529), (22, 0.08771300448430493), (23, 0.08376681614349775), (24, 0.08645739910313902), (25, 0.08538116591928249)], [(10, 0.07648114901256733), (11, 0.07648114901256733), (12, 0.07648114901256733), (13, 0.0763016157989228), (14, 0.07666068222621185), (15, 0.07648114901256733), (16, 0.07666068222621185), (17, 0.0763016157989228), (18, 0.0763016157989228), (19, 0.07648114901256733), (20, 0.07684021543985638), (21, 0.07684021543985638), (22, 0.07666068222621185), (23, 0.07666068222621185), (24, 0.07666068222621185), (25, 0.0763016157989228)]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier as mlp\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "training = KFold(n_splits=5)\n",
    "result = []\n",
    "# [DEBUG: Delete before submitting]\n",
    "counter = 1 ##\n",
    "\n",
    "for train_index, test_index in training.split(converted_data, labels):\n",
    "    text_train, text_test = converted_data_np[train_index], converted_data_np[test_index]\n",
    "    labels_train, labels_test = labels_np[train_index], labels_np[test_index]\n",
    "    avg = []\n",
    "    for i in range(10,26):\n",
    "        new_learn = mlp(solver='adam',hidden_layer_sizes=i, max_iter=3000)\n",
    "        temp = []\n",
    "        for c in range(5):\n",
    "            new_learn.fit(text_train, labels_train)\n",
    "            temp.append(1 - new_learn.score(text_test, labels_test))\n",
    "        avg.append((i, np.mean(temp)))\n",
    "        # [DEBUG: Delete before submitting]\n",
    "        print(\"Model trained with layer={}, KFold split {}\".format(i,counter)) ##\n",
    "    # [DEBUG: Delete before submitting]\n",
    "    counter += 1 ##\n",
    "    result.append(avg)\n",
    "\n",
    "print(result)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Nextly we have to find out what is the optimal value for 'hidden_layer_sizes' parameter."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best number for 'hidden_layers_sizes' parameter is: 13 (int_answer)\n",
      "-------------------------------------------------------------------\n",
      "The accuracy of the model with 'hidden_layer_sizes'=13 is 0.9226767133118048\n"
     ]
    }
   ],
   "source": [
    "from statistics import mode\n",
    "final_results = []\n",
    "answer = []\n",
    "\n",
    "# here we return all 'layers' with the smallest classification errors\n",
    "for b in result:\n",
    "    temp = []\n",
    "    for n in range(len(b)):\n",
    "        temp.append(b[n][1])\n",
    "    index_val = temp.index(np.min(temp))\n",
    "    final_results.append(b[index_val])\n",
    "\n",
    "# here we take the 'layer' parameter from the pair = i, (i,np.min(temp))\n",
    "for z in final_results:\n",
    "    answer.append(z[0])\n",
    "\n",
    "# here we calculate the most frequent 'layer', that has the lowest classification error\n",
    "int_answer = mode(answer)\n",
    "print(\"The best number for 'hidden_layers_sizes' parameter is: {} (int_answer)\".format(int_answer))\n",
    "\n",
    "good_model = mlp(solver='adam',hidden_layer_sizes=int_answer, max_iter=3000)\n",
    "good_model.fit(converted_data_np,labels_np)\n",
    "\n",
    "print(\"-------------------------------------------------------------------\", end=\"\\n\")\n",
    "print(\"The accuracy of the model with 'hidden_layer_sizes'={} is {}\".format(int_answer,good_model.score(converted_data_np,labels)))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Checking the model\n",
    "In order to check the model, we will check the 'score' on a new data set composed only of 'spam' messages."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the MLP model on completely new data set = 0.9215721464465183\n"
     ]
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "from toolbox.test import reshape_for_model\n",
    "load = read_csv(\"./data/test_spam_model.csv\")\n",
    "load_arr = []\n",
    "converted = []\n",
    "#--------------------------------------------------\n",
    "test_label = []\n",
    "#--------------------------------------------------data loading\n",
    "\n",
    "for index, row in load.iterrows():\n",
    "    load_arr.append(row['Message'])\n",
    "    if row['Category'] == \"spam\":\n",
    "        test_label.append(1)\n",
    "    else:\n",
    "        test_label.append(0)\n",
    "\n",
    "for i in range(len(load_arr)):\n",
    "    converted.append(load_arr[i].split(\" \"))\n",
    "\n",
    "#--------------------------------------------------data preparation\n",
    "\n",
    "# the result should be really close 100% mark, might not be exactly a 100% because 'spam_dic' might not contain all the words in the 'test_spam_model.csv' file\n",
    "test_spam = conversion(spam_dic, converted)\n",
    "reshape_for_model(test_spam, NR_FEATURES)\n",
    "#--------------------------------------------------scoring of the model accuracy [new data set]\n",
    "\n",
    "print(\"The accuracy of the MLP model on completely new data set = {}\".format(good_model.score(np.asarray(test_spam), test_label)))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "raw",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% raw\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from toolbox.load_assets import load_spam\n",
    "# from toolbox.prepare_data import prepare\n",
    "# from toolbox.conversion import conversion\n",
    "# from toolbox.reshape import reshape\n",
    "# from sklearn.neural_network import MLPClassifier\n",
    "# #------------------------------\n",
    "# file = \"./data/spam.csv\"\n",
    "# X = \"./data/train.csv\"\n",
    "# #------------------------------\n",
    "#\n",
    "# spam_dic = load_spam(file)\n",
    "# temp = []\n",
    "#\n",
    "# data = prepare(X,'spam_text','label')\n",
    "# text = data[0]\n",
    "# labels = data[1]\n",
    "#\n",
    "#\n",
    "# converted_data = conversion(spam_dic, text)\n",
    "# reshape(converted_data)\n",
    "#\n",
    "# mlp = MLPClassifier(solver='adam',hidden_layer_sizes=15,max_iter=3000)\n",
    "# mlp.fit(converted_data,labels)\n",
    "#\n",
    "# print(mlp.score(converted_data, labels))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}